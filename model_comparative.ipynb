{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01854fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T13:26:13.016555Z",
     "start_time": "2023-05-25T13:26:12.035585Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "# from utils import denoise_text, preprocess_text\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, RocCurveDisplay\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, \n",
    "    f1_score, accuracy_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay)\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25681e98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T13:26:14.528856Z",
     "start_time": "2023-05-25T13:26:14.217133Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mFILE\u001b[49m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FILE' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(FILE, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf27ef43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:38:56.661348Z",
     "start_time": "2023-05-14T07:38:56.659024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load label encoder\n",
    "with open('cards/models/label_encoder.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "473f7ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:11.447258Z",
     "start_time": "2023-05-14T07:39:01.965953Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_V1\n",
      "0_V1_SimCSE_RANDOM_hard_negatives\n",
      "0_V1_SimCSE_SAME_BRANCH_hard_negatives\n",
      "50_SimCSE_SAME_BRANCH_5_hard_negatives\n",
      "50_V1\n",
      "50_V2\n",
      "50_V4\n",
      "50_GPT-4_V3\n",
      "100_V2\n",
      "500_V2\n",
      "100_V3\n",
      "500_V3\n",
      "GPT-4_V2\n"
     ]
    }
   ],
   "source": [
    "# list_samples = [0, 50, 100, 200, 300, 400, \"400V2\", 500, 700, 1000]\n",
    "seed = \"9834838408490912248\"\n",
    "list_samples = [\"0V1\", \"400V1\"]\n",
    "# \"50_V2\", \"50_V3\"\n",
    "list_samples = [\n",
    "#     \"0_V1\", \"50_V1\", \"50_V2\", \"50_V2.1\", \"100_V2\", \"200_V2\"\n",
    "    \"0_V1\", \n",
    "    \"0_V1_SimCSE_RANDOM_hard_negatives\", \"0_V1_SimCSE_SAME_BRANCH_hard_negatives\",\n",
    "    \"50_SimCSE_SAME_BRANCH_5_hard_negatives\",\n",
    "    \"50_V1\", \"50_V2\", \"50_V4\", \n",
    "#     \"50_V4_base\", \n",
    "    \"50_GPT-4_V3\",\n",
    "#     \"50_V4_SimCSE_base\", \"50_V4_SimCSE_unsupervised\", \"50_V4_subsampled\", \"50_V4_SimCSE_RANDOM_hard_negatives\",\n",
    "#     \"50_V4_new_pipe\", \n",
    "    \"100_V2\", \"500_V2\", \"100_V3\", \"500_V3\", \"GPT-4_V2\"\n",
    "]\n",
    "partition = [\"TRAIN\", \"VALID\", \"TEST\"]\n",
    "f1_scores = {}\n",
    "reports = {}\n",
    "cards_data = data[(data.DATASET==\"cards\")].copy(deep=True)\n",
    "for n in list_samples:\n",
    "    print(n)\n",
    "\n",
    "    augmented_cards = pd.read_csv(f\"datasets/augmented/{seed}/cards_augmented_{n}.csv\")\n",
    "\n",
    "    for p in partition:\n",
    "        augmented_cards_partition = augmented_cards[augmented_cards.PARTITION==p]\n",
    "\n",
    "        y_true = augmented_cards_partition.claim.values\n",
    "        y_pred = augmented_cards_partition[f\"cards_aug_pred\"].values\n",
    "            \n",
    "        if p not in reports: reports[p]=[]\n",
    "        report = classification_report_df(y_true, y_pred)\n",
    "        reports[p].append(report)\n",
    "\n",
    "        if p not in f1_scores: f1_scores[p]=[]\n",
    "        f1_scores[p].append(f1_score(y_true, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65635d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:11.465008Z",
     "start_time": "2023-05-14T07:39:11.448333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_CHATGPT_V1</th>\n",
       "      <th>50_CHATGPT_V1</th>\n",
       "      <th>50_CHATGPT_V2</th>\n",
       "      <th>50_GPT-4</th>\n",
       "      <th>100_CHATGPT_V2</th>\n",
       "      <th>500_CHATGPT_V2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN</th>\n",
       "      <td>0.912146</td>\n",
       "      <td>0.911624</td>\n",
       "      <td>0.918324</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.923519</td>\n",
       "      <td>0.937209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALID</th>\n",
       "      <td>0.759789</td>\n",
       "      <td>0.753273</td>\n",
       "      <td>0.749779</td>\n",
       "      <td>0.748160</td>\n",
       "      <td>0.748263</td>\n",
       "      <td>0.733458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST</th>\n",
       "      <td>0.776857</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.775737</td>\n",
       "      <td>0.782471</td>\n",
       "      <td>0.768797</td>\n",
       "      <td>0.769878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0_CHATGPT_V1  50_CHATGPT_V1  50_CHATGPT_V2  50_GPT-4  100_CHATGPT_V2  \\\n",
       "TRAIN      0.912146       0.911624       0.918324  0.931381        0.923519   \n",
       "VALID      0.759789       0.753273       0.749779  0.748160        0.748263   \n",
       "TEST       0.776857       0.779789       0.775737  0.782471        0.768797   \n",
       "\n",
       "       500_CHATGPT_V2  \n",
       "TRAIN        0.937209  \n",
       "VALID        0.733458  \n",
       "TEST         0.769878  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(f1_scores, index=list_samples).T\n",
    "resumen = resumen[[\"0_V1\", \"50_V1\", \"50_V2\", \"50_V4\", \"100_V2\", \"500_V2\"]]\n",
    "\n",
    "cols = {}\n",
    "for c in resumen.columns:\n",
    "    if \"V1\" in c:\n",
    "        cols[c] = c.replace(\"V1\", \"CHATGPT_V1\")\n",
    "    elif \"V2\" in c:\n",
    "        cols[c] = c.replace(\"V2\", \"CHATGPT_V2\")\n",
    "    elif \"V3\" in c:\n",
    "        cols[c] = c.replace(\"V3\", \"GPT-4-TEST\")\n",
    "    elif \"V4\" in c:\n",
    "        cols[c] = c.replace(\"V4\", \"GPT-4\")\n",
    "\n",
    "resumen = resumen.rename(columns=cols)\n",
    "resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bda9ee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:11.476802Z",
     "start_time": "2023-05-14T07:39:11.465921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDS</th>\n",
       "      <th>RANDOM (1)</th>\n",
       "      <th>SAME BRANCH (1)</th>\n",
       "      <th>SAME BRANCH (2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN</th>\n",
       "      <td>0.912146</td>\n",
       "      <td>0.907953</td>\n",
       "      <td>0.914348</td>\n",
       "      <td>0.905489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALID</th>\n",
       "      <td>0.759789</td>\n",
       "      <td>0.743029</td>\n",
       "      <td>0.749685</td>\n",
       "      <td>0.755300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST</th>\n",
       "      <td>0.776857</td>\n",
       "      <td>0.766031</td>\n",
       "      <td>0.768876</td>\n",
       "      <td>0.769360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CARDS  RANDOM (1)  SAME BRANCH (1)  SAME BRANCH (2)\n",
       "TRAIN  0.912146    0.907953         0.914348         0.905489\n",
       "VALID  0.759789    0.743029         0.749685         0.755300\n",
       "TEST   0.776857    0.766031         0.768876         0.769360"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(f1_scores, index=list_samples).T\n",
    "resumen = resumen[[\n",
    "    \"0_V1\", \"0_V1_SimCSE_RANDOM_hard_negatives\", \"0_V1_SimCSE_SAME_BRANCH_hard_negatives\", \n",
    "    \"50_SimCSE_SAME_BRANCH_5_hard_negatives\"]]\n",
    "resumen = resumen.rename(columns={\n",
    "    \"0_V1\": \"CARDS\",\n",
    "    \"0_V1_SimCSE_RANDOM_hard_negatives\": \"RANDOM (1)\",\n",
    "    \"0_V1_SimCSE_SAME_BRANCH_hard_negatives\": \"SAME BRANCH (1)\",\n",
    "    \"50_SimCSE_SAME_BRANCH_5_hard_negatives\": \"SAME BRANCH (2)\"\n",
    "})\n",
    "resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fae4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:11.486250Z",
     "start_time": "2023-05-14T07:39:11.477777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDS</th>\n",
       "      <th>GPT-4 (1)</th>\n",
       "      <th>GPT-4 (2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN</th>\n",
       "      <td>0.912146</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.910369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALID</th>\n",
       "      <td>0.759789</td>\n",
       "      <td>0.748160</td>\n",
       "      <td>0.749628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST</th>\n",
       "      <td>0.776857</td>\n",
       "      <td>0.782471</td>\n",
       "      <td>0.750774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CARDS  GPT-4 (1)  GPT-4 (2)\n",
       "TRAIN  0.912146   0.931381   0.910369\n",
       "VALID  0.759789   0.748160   0.749628\n",
       "TEST   0.776857   0.782471   0.750774"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen = pd.DataFrame(f1_scores, index=list_samples).T\n",
    "resumen = resumen[[\n",
    "    \"0_V1\", \"50_V4\", \"50_GPT-4_V3\"]]\n",
    "resumen = resumen.rename(columns={\n",
    "    \"0_V1\": \"CARDS\",\n",
    "    \"50_V4\": \"GPT-4 (1)\",\n",
    "    \"50_GPT-4_V3\": \"GPT-4 (2)\",\n",
    "})\n",
    "resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e71265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.820069Z",
     "start_time": "2023-05-14T07:39:11.487245Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['0_V1', '50_V4', '50_GPT-4_V3'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [red \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(v)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m green \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m----> 8\u001b[0m submpling_exp \u001b[38;5;241m=\u001b[39m \u001b[43mresumen\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0_V1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m50_V4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m50_GPT-4_V3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m submpling_exp\n",
      "File \u001b[0;32m/opt/conda/envs/uni/lib/python3.8/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/uni/lib/python3.8/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/uni/lib/python3.8/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['0_V1', '50_V4', '50_GPT-4_V3'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def styling(data):\n",
    "    red = 'background-color: #f8d2d2'\n",
    "    green = 'background-color: #d2f8d2'\n",
    "    if data.name==\"diff\":\n",
    "        return [red if float(v)<0 else green for v in data]\n",
    "    return [None for v in data]\n",
    "\n",
    "submpling_exp = resumen[[\"0_V1\", \"50_V4\", \"50_GPT-4_V3\"]]\n",
    "submpling_exp\n",
    "# submpling_exp[\"diff\"] = submpling_exp.iloc[:, 1] - submpling_exp.iloc[:, 0]\n",
    "# submpling_exp.style.apply(styling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9a2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.822591Z",
     "start_time": "2023-05-14T07:39:12.822582Z"
    }
   },
   "outputs": [],
   "source": [
    "submpling_exp = resumen[[\"0_CHATGPT_V1\", \"50_GPT-4\", \"\"]]\n",
    "submpling_exp[\"diff\"] = submpling_exp.iloc[:, 1] - submpling_exp.iloc[:, 0]\n",
    "submpling_exp.style.apply(styling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3271a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.823313Z",
     "start_time": "2023-05-14T07:39:12.823305Z"
    }
   },
   "outputs": [],
   "source": [
    "submpling_exp = resumen[[\"50_GPT-4_base\", \"50_GPT-4_SimCSE_base\"]]\n",
    "submpling_exp[\"diff\"] = submpling_exp.iloc[:, 1] - submpling_exp.iloc[:, 0]\n",
    "submpling_exp.style.apply(styling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015e343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.824103Z",
     "start_time": "2023-05-14T07:39:12.824096Z"
    }
   },
   "outputs": [],
   "source": [
    "submpling_exp = resumen[[\"50_GPT-4\", \"50_GPT-4_SimCSE_unsupervised\"]]\n",
    "submpling_exp[\"diff\"] = submpling_exp.iloc[:, 1] - submpling_exp.iloc[:, 0]\n",
    "submpling_exp.style.apply(styling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bcb26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.824822Z",
     "start_time": "2023-05-14T07:39:12.824815Z"
    }
   },
   "outputs": [],
   "source": [
    "resumen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f771c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.825404Z",
     "start_time": "2023-05-14T07:39:12.825397Z"
    }
   },
   "outputs": [],
   "source": [
    "submpling_exp = resumen[[\n",
    "    \"0_V1\", \n",
    "    \"0_V1_SimCSE_RANDOM_hard_negatives\",\n",
    "    \"0_V1_SimCSE_SAME_BRANCH_hard_negatives\"\n",
    "]]\n",
    "# submpling_exp[\"diff\"] = submpling_exp.iloc[:, 1] - submpling_exp.iloc[:, 0]\n",
    "# submpling_exp.style.apply(styling, axis=0)\n",
    "submpling_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d19044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.826257Z",
     "start_time": "2023-05-14T07:39:12.826249Z"
    }
   },
   "outputs": [],
   "source": [
    "submpling_exp = resumen[[\"50_GPT-4\", \"50_GPT-4_SimCSE_RANDOM_hard_negatives\"]]\n",
    "submpling_exp = submpling_exp.rename(columns={\n",
    "    \"50_GPT-4\": \"0_V1\", \n",
    "    \"50_GPT-4_SimCSE_RANDOM_hard_negatives\": \"0_V1_SimCSE_SAME_BRANCH_hard_negatives\"})\n",
    "submpling_exp[\"diff\"] = submpling_exp.iloc[:, 1] - submpling_exp.iloc[:, 0]\n",
    "submpling_exp.style.apply(styling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea483e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.826799Z",
     "start_time": "2023-05-14T07:39:12.826792Z"
    }
   },
   "outputs": [],
   "source": [
    "submpling_exp = resumen[[\"50_GPT-4\", \"50_GPT-4_new_pipe\"]]\n",
    "submpling_exp[\"diff\"] = submpling_exp.iloc[:, 1] - submpling_exp.iloc[:, 0]\n",
    "submpling_exp.style.apply(styling, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ca7c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.827341Z",
     "start_time": "2023-05-14T07:39:12.827334Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5), dpi=80)\n",
    "for p in partition[1:]:\n",
    "    plt.plot(list_samples, f1_scores[p], label=p)\n",
    "plt.title(\"F1-score vs Data Augmented\")\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xlabel('N. Samples Generated')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6a844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.828023Z",
     "start_time": "2023-05-14T07:39:12.828016Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classes = le.classes_\n",
    "coms = pd.DataFrame()\n",
    "coms[\"support\"] = data[\n",
    "    (data.PARTITION==\"TRAIN\")&(data.DATASET==\"cards\")].claim.value_counts().sort_index().values\n",
    "for i, n in enumerate(list_samples[1:]):\n",
    "    aug = reports[\"VALID\"][i+1][[\"f1-score\"]].astype(float).values\n",
    "    base = reports[\"VALID\"][0][[\"f1-score\"]].astype(float).values\n",
    "    diff = (aug - base).flatten()\n",
    "    \n",
    "    coms[n] = diff[:18] \n",
    "#     print(n)\n",
    "#     print(n, classes[diff[:18]>0.])\n",
    "#     print(sum(diff[:18]))\n",
    "#     print(diff)\n",
    "#     print(sum(diff[diff>0.][:18]))\n",
    "#     print()\n",
    "coms[\"generated\"] = report_generated[\"f1-score\"][:18].apply(float)\n",
    "coms.index = classes\n",
    "coms.loc[\"sum\", :] = coms.sum()\n",
    "coms\n",
    "\n",
    "red = 'background-color: #f8d2d2'\n",
    "green = 'background-color: #d2f8d2'\n",
    "coms.style.apply(\n",
    "    lambda data, color: [red if float(v)<0 else green for v in data], \n",
    "                 color='darkorange', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1382c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.828794Z",
     "start_time": "2023-05-14T07:39:12.828784Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_cards[(augmented_cards.claim == \"4_5\")&(augmented_cards.DATASET == \"generated-gpt-4\")].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e58f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.829416Z",
     "start_time": "2023-05-14T07:39:12.829405Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/augmented/9834838408490912248/cards_augmented_50_V3_9834838408490912248.csv\")\n",
    "generated = pd.read_csv(\"datasets/generated_disinformation_taxonomy_CARDS_GPT-4_specific_samples_V2.csv\")\n",
    "# for class_ in le.classes_[1:]:\n",
    "dataset[\"based_claims\"] = None\n",
    "dataset.loc[(dataset.claim==\"4_5\")&(dataset.DATASET==\"generated-gpt-4\"), \"based_claims\"] = generated.loc[(generated.generated_label==\"4_5\"), \"based_claims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae34fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.830064Z",
     "start_time": "2023-05-14T07:39:12.830055Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[(dataset.claim==\"4_5\")&(dataset.DATASET==\"generated-gpt-4\")][[\"text\", \"claim\", \"cards_aug_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc0cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.830629Z",
     "start_time": "2023-05-14T07:39:12.830621Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_index = augmented_cards[(augmented_cards.claim == \"4_5\")&(augmented_cards.cards_aug_pred != \"4_5\")&(augmented_cards.PARTITION == \"TEST\")][[\"text\", \"cards_aug_pred\"]].index\n",
    "\n",
    "generated_4_5 = generated.loc[(generated.generated_label==\"4_5\")]\n",
    "generated_4_5[generated_4_5.based_claims.apply(lambda x: any([True if i in bad_index else False for i in eval(x)]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d7f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.831239Z",
     "start_time": "2023-05-14T07:39:12.831232Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = le.classes_\n",
    "coms = pd.DataFrame()\n",
    "coms[\"support\"] = data[\n",
    "    (data.PARTITION==\"TRAIN\")&(data.DATASET==\"cards\")].claim.value_counts().sort_index().values\n",
    "for i, n in enumerate(list_samples[1:]):\n",
    "    aug = reports[\"TEST\"][i+1][[\"f1-score\"]].astype(float).values\n",
    "    base = reports[\"TEST\"][0][[\"f1-score\"]].astype(float).values\n",
    "    diff = (aug - base).flatten()\n",
    "    \n",
    "    coms[n] = diff[:18]\n",
    "#     print(n)\n",
    "    print(n, classes[diff[:18]>0.])\n",
    "#     print(sum(diff[:18]))\n",
    "#     print(diff)\n",
    "#     print(sum(diff[diff>0.][:18]))\n",
    "#     print()\n",
    "coms[\"generated\"] = report_generated[\"f1-score\"][:18].apply(float)\n",
    "coms.index = classes\n",
    "coms.loc[\"average\", :] = coms.sum()\n",
    "coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f026b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.831740Z",
     "start_time": "2023-05-14T07:39:12.831733Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n in list_samples[1:]:\n",
    "    augmented_cards = pd.read_csv(f\"datasets/cards_augmented_{n}.csv\")\n",
    "    augmented_cards_test = augmented_cards[augmented_cards.PARTITION==\"TEST\"]\n",
    "\n",
    "    y_true = augmented_cards_test.claim.values\n",
    "    y_pred = augmented_cards_test[f\"cards_aug_{n}_pred\"].values\n",
    "\n",
    "    report = classification_report_df(y_true, y_pred)\n",
    "    display(Markdown(f\"### n={n}\"))\n",
    "    display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019bd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.832296Z",
     "start_time": "2023-05-14T07:39:12.832285Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_scores[\"VALID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12c893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.833086Z",
     "start_time": "2023-05-14T07:39:12.833079Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_scores[\"TEST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd42a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.833579Z",
     "start_time": "2023-05-14T07:39:12.833572Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "VERSION = 1\n",
    "augmented_cards = pd.read_csv(f\"datasets/augmented/cards_augmented_{n}V{VERSION}.csv\")\n",
    "augmented_cards_test = augmented_cards[augmented_cards.PARTITION==\"TEST\"]\n",
    "\n",
    "y_true = augmented_cards_test.claim.values\n",
    "y_pred = augmented_cards_test[f\"cards_aug_{n}V{VERSION}_pred\"].values\n",
    "\n",
    "print(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "report = classification_report_df(y_true, y_pred)\n",
    "display(Markdown(f\"### n={n}\"))\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e492d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.834128Z",
     "start_time": "2023-05-14T07:39:12.834114Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 400\n",
    "VERSION = 1\n",
    "augmented_cards = pd.read_csv(f\"datasets/augmented/cards_augmented_{n}V{VERSION}.csv\")\n",
    "augmented_cards_test = augmented_cards[augmented_cards.PARTITION==\"TEST\"]\n",
    "\n",
    "y_true = augmented_cards_test.claim.values\n",
    "y_pred = augmented_cards_test[f\"cards_aug_{n}V{VERSION}_pred\"].values\n",
    "\n",
    "print(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "report = classification_report_df(y_true, y_pred)\n",
    "display(Markdown(f\"### n={n}\"))\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf822f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.834606Z",
     "start_time": "2023-05-14T07:39:12.834599Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 400\n",
    "VERSION = \"V5\"\n",
    "augmented_cards = pd.read_csv(f\"datasets/augmented/cards_augmented_{n}{VERSION}.csv\")\n",
    "augmented_cards_test = augmented_cards[augmented_cards.PARTITION==\"TEST\"]\n",
    "\n",
    "y_true = augmented_cards_test.claim.values\n",
    "y_pred = augmented_cards_test[f\"cards_aug_{n}{VERSION}_pred\"].values\n",
    "\n",
    "print(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "report = classification_report_df(y_true, y_pred)\n",
    "display(Markdown(f\"### n={n}\"))\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f480c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.835432Z",
     "start_time": "2023-05-14T07:39:12.835422Z"
    }
   },
   "outputs": [],
   "source": [
    "comparative = pd.read_csv(f\"datasets/augmented/cards_augmented_400.csv\")\n",
    "comparative = comparative.iloc[:,1:]\n",
    "tmp = pd.read_csv(f\"datasets/augmented/cards_augmented_400V2.csv\")\n",
    "comparative[\"cards_aug_400V2_pred\"] = tmp[\"cards_aug_400V2_pred\"]\n",
    "comparative[\"cards_aug_400V2_proba\"] = tmp[\"cards_aug_400V2_proba\"]\n",
    "\n",
    "comparative[\"cards_aug_400_proba\"] = comparative[\"cards_aug_400_proba\"].apply(format_scores)\n",
    "comparative[\"cards_aug_400V2_proba\"] = comparative[\"cards_aug_400V2_proba\"].apply(format_scores)\n",
    "\n",
    "comparative[\"cards_aug_400_score\"] = comparative.apply(\n",
    "    lambda x: x[\"cards_aug_400_proba\"][le.transform([x[\"cards_aug_400_pred\"]])[0]], axis=1)\n",
    "\n",
    "comparative[\"cards_aug_400V2_score\"] = comparative.apply(\n",
    "    lambda x: x[\"cards_aug_400V2_proba\"][le.transform([x[\"cards_aug_400V2_pred\"]])[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da552e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.836061Z",
     "start_time": "2023-05-14T07:39:12.836054Z"
    }
   },
   "outputs": [],
   "source": [
    "comparative_test = comparative[comparative.PARTITION==\"TEST\"]\n",
    "comparative_test[\n",
    "    (comparative_test.claim==\"4_5\")&(comparative_test.cards_aug_400_pred!=comparative_test.cards_aug_400V2_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23cfd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.836711Z",
     "start_time": "2023-05-14T07:39:12.836702Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_cards = pd.read_csv(f\"datasets/augmented/cards_augmented_50_filteredV2.csv\")\n",
    "augmented_cards_test = augmented_cards[augmented_cards.PARTITION==\"TEST\"]\n",
    "\n",
    "y_true = augmented_cards_test.claim.values\n",
    "y_pred = augmented_cards_test[f\"cards_aug_50_pred\"].values\n",
    "\n",
    "report = classification_report_df(y_true, y_pred)\n",
    "display(Markdown(f\"### n=50\"))\n",
    "print(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb381b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.837441Z",
     "start_time": "2023-05-14T07:39:12.837434Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_cards[\n",
    "    (augmented_cards.DATASET==\"generated-chatgpt\")&(augmented_cards.labels==\"1_4\")].cards_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ac6d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.838403Z",
     "start_time": "2023-05-14T07:39:12.838394Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generated_taxonomy = pd.read_csv(\"datasets/generated_disinformation_taxonomy_CARDS_CHATGPT_specific_samples_predict.csv\")\n",
    "\n",
    "# generated_taxonomy = generated_taxonomy[\n",
    "#     generated_taxonomy.generated_label.isin([\"1_1\", \"1_2\", \"1_3\", \"1_4\", \"1_6\", \"1_7\", \"2_1\"])]\n",
    "\n",
    "y_true = generated_taxonomy.generated_label.values\n",
    "y_pred = generated_taxonomy.cards_pred.values\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)\n",
    "\n",
    "classes = np.sort(generated_taxonomy.cards_pred.unique())\n",
    "c_m = confusion_matrix(y_true, y_pred)\n",
    "cmp = ConfusionMatrixDisplay(\n",
    "    c_m, display_labels=classes)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "cmp.plot(ax=ax)  \n",
    "\n",
    "\n",
    "report = classification_report_df(y_true, y_pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434802c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.838995Z",
     "start_time": "2023-05-14T07:39:12.838987Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_taxonomy = pd.read_csv(\"datasets/generated_disinformation_taxonomy_CARDS_CHATGPT_specific_samples_V2.csv\")\n",
    "\n",
    "y_true = generated_taxonomy.generated_label.values\n",
    "y_pred = generated_taxonomy.cards_pred.values\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)\n",
    "\n",
    "classes = np.sort(generated_taxonomy.cards_pred.unique())\n",
    "c_m = confusion_matrix(y_true, y_pred)\n",
    "cmp = ConfusionMatrixDisplay(\n",
    "    c_m, display_labels=classes)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "cmp.plot(ax=ax)  \n",
    "\n",
    "\n",
    "report = classification_report_df(y_true, y_pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db428e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.839571Z",
     "start_time": "2023-05-14T07:39:12.839564Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = cards_data.claim.values\n",
    "y_pred = cards_data.sec_clf_roberta_pred.values\n",
    "\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1fcc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:39:12.840232Z",
     "start_time": "2023-05-14T07:39:12.840225Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_generated = pd.read_csv(\"datasets/generated_disinformation_binary_TEST_CHATGPT.csv\", low_memory=False)\n",
    "test_generated[\"roberta_proba\"] = test_generated[\"roberta_proba\"].apply(format_scores)\n",
    "test_generated[\"aug_roberta_proba\"] = test_generated[\"aug_roberta_proba\"].apply(format_scores)\n",
    "test_generated[\"labels\"] = 1\n",
    "\n",
    "display(Markdown(f\"### Randomly Generated TEST CHATGPT\"))\n",
    "models_comparative(test_generated, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
