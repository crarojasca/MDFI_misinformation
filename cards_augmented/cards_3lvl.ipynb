{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0bdc03-5702-4bdf-92a6-47b99860fe17",
   "metadata": {},
   "source": [
    "# Third LVL Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae165196-89ac-438b-a01f-49e2fd103c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941b5f0-8fa1-4981-a23e-750566ef6c61",
   "metadata": {},
   "source": [
    "## Read Base Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aea59723-d666-4a30-b9be-3f45fdb920c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json(\"../datasets/third_level/cards_annotations.json\")\n",
    "# data = data.rename(columns={\n",
    "#     \"Paragraph_Text\": \"text\",\n",
    "#     \"sub_claim\": \"claim\",\n",
    "#     \"sub_sub_claim\": \"sub_claim\"\n",
    "# })\n",
    "# data.head()\n",
    "\n",
    "# # PARTITIONS DATA\n",
    "# cards_data = pd.read_csv(\"../datasets/CARDS_scored.csv\", low_memory=False)\n",
    "# cards_data = cards_data.rename(columns={\"claim\": \"cards_claim\"})\n",
    "# data = data.merge(cards_data[[\"text\", \"PARTITION\", \"cards_claim\"]], left_on=\"text\", right_on=\"text\", how=\"left\")\n",
    "\n",
    "# third_lvl_nacount = data[data[\"PARTITION\"].isna()][\"sub_claim\"].value_counts().reset_index()\n",
    "# classes_to_filter = third_lvl_nacount[third_lvl_nacount[\"sub_claim\"]<2][\"index\"].tolist()\n",
    "# data.loc[(data[\"PARTITION\"].isna())&(data[\"sub_claim\"].isin(classes_to_filter)), \"PARTITION\"] = \"TRAIN\"\n",
    "\n",
    "# nullp_data = data[data[\"PARTITION\"].isna()]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     nullp_data[\"text\"], nullp_data[\"sub_claim\"], \n",
    "#     stratify=nullp_data[\"sub_claim\"], test_size=0.20, random_state=42)\n",
    "\n",
    "# data.loc[data[\"text\"].isin(X_train)&data[\"PARTITION\"].isna(), \"PARTITION\"] = \"TRAIN\"\n",
    "\n",
    "# third_lvl_nacount = data[data[\"PARTITION\"].isna()][\"sub_claim\"].value_counts().reset_index()\n",
    "# classes_to_filter = third_lvl_nacount[third_lvl_nacount[\"sub_claim\"]<2][\"index\"].tolist()\n",
    "# data.loc[data[\"PARTITION\"].isna()&data[\"sub_claim\"].isin(classes_to_filter), \"PARTITION\"] = \"TEST\"\n",
    "\n",
    "# nullp_data = data[data[\"PARTITION\"].isna()]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     nullp_data[\"text\"], nullp_data[\"sub_claim\"], \n",
    "#     stratify=nullp_data[\"sub_claim\"], test_size=0.50, random_state=42)\n",
    "\n",
    "# data.loc[data[\"text\"].isin(X_train)&data[\"PARTITION\"].isna(), \"PARTITION\"] = \"VALID\"\n",
    "# data.loc[data[\"text\"].isin(X_test)&data[\"PARTITION\"].isna(), \"PARTITION\"] = \"TEST\"\n",
    "\n",
    "# test_sample = data[(data[\"sub_claim\"]==\"5.3.0\")&(data[\"PARTITION\"]==\"TRAIN\")].sample(1)\n",
    "# data.loc[test_sample.index, \"PARTITION\"] = \"TEST\"\n",
    "# valid_sample = data[(data[\"sub_claim\"]==\"5.3.0\")&(data[\"PARTITION\"]==\"TRAIN\")].sample(3)\n",
    "# data.loc[valid_sample.index, \"PARTITION\"] = \"VALID\"\n",
    "\n",
    "# data[\"claim\"] = data[\"claim\"].astype(str).str.replace(\".\", \"_\")\n",
    "# data[\"sub_claim\"] = data[\"sub_claim\"].astype(str).str.replace(\".\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bca1fe8-235a-4461-8607-213f890f5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParagraphId', 'text', 'phase', 'claim', 'sub_claim', 'tokens',\n",
       "       'PARTITION', 'cards_claim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "086885a3-c0d2-47ce-99b5-369496d9346c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParagraphId</th>\n",
       "      <th>text</th>\n",
       "      <th>phase</th>\n",
       "      <th>parent_claim</th>\n",
       "      <th>sub_claim</th>\n",
       "      <th>tokens</th>\n",
       "      <th>PARTITION</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Hmm. No lepers bell there. But perhaps Tim Fla...</td>\n",
       "      <td>1</td>\n",
       "      <td>5_2</td>\n",
       "      <td>5_2_5</td>\n",
       "      <td>hmm lepers bell perhaps tim flannery introduce...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004</td>\n",
       "      <td>Presumably somebody added the line and in doin...</td>\n",
       "      <td>1</td>\n",
       "      <td>5_2</td>\n",
       "      <td>5_2_5</td>\n",
       "      <td>presumably somebody added line provided genera...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>This period of widespread warmth is notable in...</td>\n",
       "      <td>1</td>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1_4</td>\n",
       "      <td>period widespread warmth notable evidence acco...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>All these points confronted and contradicted t...</td>\n",
       "      <td>1</td>\n",
       "      <td>5_1</td>\n",
       "      <td>5_1_2</td>\n",
       "      <td>points confronted contradicted political agend...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1078</td>\n",
       "      <td>Cost to \"avoid\" global warming: $1.3 Quadrilli...</td>\n",
       "      <td>1</td>\n",
       "      <td>4_1</td>\n",
       "      <td>4_1_1</td>\n",
       "      <td>cost avoid global warming $ 1.3 quadrillion pe...</td>\n",
       "      <td>VALID</td>\n",
       "      <td>4_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParagraphId                                               text  phase  \\\n",
       "0           10  Hmm. No lepers bell there. But perhaps Tim Fla...      1   \n",
       "1         1004  Presumably somebody added the line and in doin...      1   \n",
       "2         1005  This period of widespread warmth is notable in...      1   \n",
       "3         1013  All these points confronted and contradicted t...      1   \n",
       "4         1078  Cost to \"avoid\" global warming: $1.3 Quadrilli...      1   \n",
       "\n",
       "  parent_claim sub_claim                                             tokens  \\\n",
       "0          5_2     5_2_5  hmm lepers bell perhaps tim flannery introduce...   \n",
       "1          5_2     5_2_5  presumably somebody added line provided genera...   \n",
       "2          2_1     2_1_4  period widespread warmth notable evidence acco...   \n",
       "3          5_1     5_1_2  points confronted contradicted political agend...   \n",
       "4          4_1     4_1_1  cost avoid global warming $ 1.3 quadrillion pe...   \n",
       "\n",
       "  PARTITION claim  \n",
       "0     TRAIN   5_2  \n",
       "1     TRAIN   5_2  \n",
       "2     TRAIN   2_1  \n",
       "3     TRAIN   5_1  \n",
       "4     VALID   4_1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/third_level/cards_complete.csv\")\n",
    "data.loc[data[\"parent_claim\"]==\"5_3\", \"cards_claim\"] = \"5_3\"\n",
    "data = data.rename(columns={\"claim\":\"sub_claim\", \"cards_claim\" : \"claim\"})\n",
    "# data = data[data[\"claim\"]!=\"0_0\"]\n",
    "data = data[ ~data[\"claim\"].isna()]\n",
    "# data = data[[\"text\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "996e4fe9-355a-415b-9ec6-116303f1e227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0_0    19783\n",
       "5_1     1717\n",
       "2_1      984\n",
       "5_2      851\n",
       "1_4      596\n",
       "1_7      528\n",
       "3_2      423\n",
       "5_3      422\n",
       "2_3      421\n",
       "1_1      417\n",
       "4_1      416\n",
       "3_3      400\n",
       "4_4      306\n",
       "1_3      283\n",
       "3_1      255\n",
       "4_2      239\n",
       "1_6      233\n",
       "4_5      232\n",
       "1_2      180\n",
       "Name: claim, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"claim\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3324b6f4-b128-4632-8d2c-836573db4e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    28686\n",
       "Name: claim, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"claim\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9091e653-5601-4f1c-925d-a95b4a07b03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"claim\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "80efb47b-64d9-46a3-a626-761ca0a8bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../datasets/third_level/cards_5.3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fd5f8d1-0379-4456-827c-5d3331b69f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2.4', '1.8.0', '4.3.0', '4.2.7', '4.1.2', '4.1.4']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_to_filter = third_lvl_count[third_lvl_count[\"sub_sub_claim\"]<10][\"index\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e645374-fa43-4251-9514-af4f438b2862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParagraphId</th>\n",
       "      <th>text</th>\n",
       "      <th>phase</th>\n",
       "      <th>parent_claim</th>\n",
       "      <th>claim</th>\n",
       "      <th>tokens</th>\n",
       "      <th>PARTITION</th>\n",
       "      <th>cards_claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Hmm. No lepers bell there. But perhaps Tim Fla...</td>\n",
       "      <td>1</td>\n",
       "      <td>5_2</td>\n",
       "      <td>5_2_5</td>\n",
       "      <td>hmm lepers bell perhaps tim flannery introduce...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004</td>\n",
       "      <td>Presumably somebody added the line and in doin...</td>\n",
       "      <td>1</td>\n",
       "      <td>5_2</td>\n",
       "      <td>5_2_5</td>\n",
       "      <td>presumably somebody added line provided genera...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>This period of widespread warmth is notable in...</td>\n",
       "      <td>1</td>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1_4</td>\n",
       "      <td>period widespread warmth notable evidence acco...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>All these points confronted and contradicted t...</td>\n",
       "      <td>1</td>\n",
       "      <td>5_1</td>\n",
       "      <td>5_1_2</td>\n",
       "      <td>points confronted contradicted political agend...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1078</td>\n",
       "      <td>Cost to \"avoid\" global warming: $1.3 Quadrilli...</td>\n",
       "      <td>1</td>\n",
       "      <td>4_1</td>\n",
       "      <td>4_1_1</td>\n",
       "      <td>cost avoid global warming $ 1.3 quadrillion pe...</td>\n",
       "      <td>VALID</td>\n",
       "      <td>4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28902</th>\n",
       "      <td>263049</td>\n",
       "      <td>In fact, we cannot even build wind and solar f...</td>\n",
       "      <td>3</td>\n",
       "      <td>4_4</td>\n",
       "      <td>4_4_1</td>\n",
       "      <td>fact even build wind solar facilities without ...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>4_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28903</th>\n",
       "      <td>263050</td>\n",
       "      <td>To summarize, industrialized countries indeed ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4_1</td>\n",
       "      <td>4_1_0</td>\n",
       "      <td>summarize industrialized countries indeed hist...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28904</th>\n",
       "      <td>263054</td>\n",
       "      <td>Whatever the weather is, they will rationalize...</td>\n",
       "      <td>3</td>\n",
       "      <td>5_1</td>\n",
       "      <td>5_1_0</td>\n",
       "      <td>whatever weather rationalize caused global war...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28905</th>\n",
       "      <td>263060</td>\n",
       "      <td>Because the model simulations have difficultie...</td>\n",
       "      <td>3</td>\n",
       "      <td>5_1</td>\n",
       "      <td>5_1_4</td>\n",
       "      <td>model simulations difficulties reproducing mea...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28906</th>\n",
       "      <td>263064</td>\n",
       "      <td>Second, because of the models are biased towar...</td>\n",
       "      <td>3</td>\n",
       "      <td>5_1</td>\n",
       "      <td>5_1_4</td>\n",
       "      <td>second models biased toward northern hemispher...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28907 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ParagraphId                                               text  phase  \\\n",
       "0               10  Hmm. No lepers bell there. But perhaps Tim Fla...      1   \n",
       "1             1004  Presumably somebody added the line and in doin...      1   \n",
       "2             1005  This period of widespread warmth is notable in...      1   \n",
       "3             1013  All these points confronted and contradicted t...      1   \n",
       "4             1078  Cost to \"avoid\" global warming: $1.3 Quadrilli...      1   \n",
       "...            ...                                                ...    ...   \n",
       "28902       263049  In fact, we cannot even build wind and solar f...      3   \n",
       "28903       263050  To summarize, industrialized countries indeed ...      3   \n",
       "28904       263054  Whatever the weather is, they will rationalize...      3   \n",
       "28905       263060  Because the model simulations have difficultie...      3   \n",
       "28906       263064  Second, because of the models are biased towar...      3   \n",
       "\n",
       "      parent_claim  claim                                             tokens  \\\n",
       "0              5_2  5_2_5  hmm lepers bell perhaps tim flannery introduce...   \n",
       "1              5_2  5_2_5  presumably somebody added line provided genera...   \n",
       "2              2_1  2_1_4  period widespread warmth notable evidence acco...   \n",
       "3              5_1  5_1_2  points confronted contradicted political agend...   \n",
       "4              4_1  4_1_1  cost avoid global warming $ 1.3 quadrillion pe...   \n",
       "...            ...    ...                                                ...   \n",
       "28902          4_4  4_4_1  fact even build wind solar facilities without ...   \n",
       "28903          4_1  4_1_0  summarize industrialized countries indeed hist...   \n",
       "28904          5_1  5_1_0  whatever weather rationalize caused global war...   \n",
       "28905          5_1  5_1_4  model simulations difficulties reproducing mea...   \n",
       "28906          5_1  5_1_4  second models biased toward northern hemispher...   \n",
       "\n",
       "      PARTITION cards_claim  \n",
       "0         TRAIN         5_2  \n",
       "1         TRAIN         5_2  \n",
       "2         TRAIN         2_1  \n",
       "3         TRAIN         5_1  \n",
       "4         VALID         4_1  \n",
       "...         ...         ...  \n",
       "28902     TRAIN         4_4  \n",
       "28903      TEST         4_1  \n",
       "28904     TRAIN         5_1  \n",
       "28905     TRAIN         5_1  \n",
       "28906     TRAIN         5_1  \n",
       "\n",
       "[28907 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a07452-1684-4a86-ba3f-1be6920d003a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
